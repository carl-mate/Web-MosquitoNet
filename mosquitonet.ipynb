{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5fda0e8-f314-475a-9010-385ce41a9050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cmate\\Projects\\School\\CMSC 199.2\\mosquitonet\\my_env\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pylab\n",
    "import io\n",
    "import json\n",
    "import math\n",
    "\n",
    "from io import BytesIO\n",
    "import base64\n",
    "from werkzeug.utils import secure_filename\n",
    "from flask import Flask, request, jsonify, url_for, render_template\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from matplotlib import cm\n",
    "from librosa import display\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdc6b1e2-4543-42a8-9b12-53c0ce34a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_EXTENSION = set(['wav'])\n",
    "IMAGE_SIZE = (300, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e60fdb5e-8034-4d9d-b6c1-a3c14eaeb97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splice(audio):\n",
    "    my_audio = AudioSegment.from_file(audio, \"wav\")\n",
    "    chunk_length_ms = 1920\n",
    "    chunks = make_chunks(my_audio, chunk_length_ms) #Make chunks of 1.92s\n",
    "    chunk_list = []\n",
    "    for chunk in chunks:\n",
    "        # Ignore audio that are less than 1.92s\n",
    "        if not math.isclose(chunk.duration_seconds, 1.92) and float(chunk.duration_seconds) < 1.92:\n",
    "            continue\n",
    "        chunk_list.append(chunk.export(BytesIO(), format=\"wav\"))\n",
    "    return chunk_list\n",
    "\n",
    "def convert_logmel(chunks):\n",
    "    converted_chunks = []\n",
    "    nfft = 2048\n",
    "    hop_length = 512\n",
    "    n_mels = 128\n",
    "    w = 30\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        x, sr = librosa.load(chunk, sr=8000)\n",
    "        L = librosa.feature.melspectrogram(y=x, sr=sr, n_mels=n_mels, n_fft=nfft, window=w, hop_length=hop_length)\n",
    "        log_power = librosa.power_to_db(L, ref=np.max)\n",
    "        pylab.figure(figsize=(3,3))\n",
    "        pylab.axis('off') \n",
    "        pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[]) # Remove the white edge\n",
    "        librosa.display.specshow(log_power, cmap=cm.jet)\n",
    "        buf = BytesIO()\n",
    "        pylab.savefig(buf, bbox_inches=None, pad_inches=0, format=\"jpg\")\n",
    "        buf.seek(0)\n",
    "        converted_chunks.append(buf)\n",
    "    return converted_chunks\n",
    "\n",
    "def convert_mfcc(chunks):\n",
    "    converted_chunks = []\n",
    "    nfft = 2048\n",
    "    hop_length = 512\n",
    "    n_mfcc = 13 # 13 - 20 mfcc\n",
    "    n_mels = 128\n",
    "    w = 30\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        x, sr = librosa.load(chunk, sr=8000)\n",
    "        M = librosa.feature.mfcc(y=x, sr=sr, n_mfcc=n_mfcc, n_mels=n_mels, n_fft=nfft, window=w, hop_length=hop_length)\n",
    "        pylab.figure(figsize=(3,3))\n",
    "        pylab.axis('off') \n",
    "        pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[]) # Remove the white edge\n",
    "        librosa.display.specshow(M, cmap=cm.jet)\n",
    "        buf = BytesIO()\n",
    "        pylab.savefig(buf, bbox_inches=None, pad_inches=0, format=\"jpg\")\n",
    "        buf.seek(0)\n",
    "        converted_chunks.append(buf)\n",
    "    return converted_chunks\n",
    "\n",
    "def convert_logmel_display(audio):\n",
    "    nfft = 2048\n",
    "    hop_length = 512\n",
    "    n_mels = 128\n",
    "    w = 30\n",
    "    \n",
    "    x, sr = librosa.load(audio, sr=8000)\n",
    "    L = librosa.feature.melspectrogram(y=x, sr=sr, n_mels=n_mels, n_fft=nfft, window=w, hop_length=hop_length)\n",
    "    log_power = librosa.power_to_db(L, ref=np.max)\n",
    "    pylab.figure(figsize=(3,3))\n",
    "    pylab.axis('off') \n",
    "    pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[]) # Remove the white edge\n",
    "    librosa.display.specshow(log_power, cmap=cm.jet)\n",
    "    buf = BytesIO()\n",
    "    pylab.savefig(buf, bbox_inches=None, pad_inches=0, format=\"jpg\")\n",
    "    buf.seek(0)\n",
    "    return buf\n",
    "\n",
    "def convert_mfcc_display(audio):\n",
    "    nfft = 2048\n",
    "    hop_length = 512\n",
    "    n_mfcc = 13 # 13 - 20 mfcc\n",
    "    n_mels = 128\n",
    "    w = 30\n",
    "    \n",
    "    x, sr = librosa.load(audio, sr=8000)\n",
    "    M = librosa.feature.mfcc(y=x, sr=sr, n_mfcc=n_mfcc, n_mels=n_mels, n_fft=nfft, window=w, hop_length=hop_length)\n",
    "    pylab.figure(figsize=(3,3))\n",
    "    pylab.axis('off') \n",
    "    pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[]) # Remove the white edge\n",
    "    librosa.display.specshow(M, cmap=cm.jet)\n",
    "    buf = BytesIO()\n",
    "    pylab.savefig(buf, bbox_inches=None, pad_inches=0, format=\"jpg\")\n",
    "    buf.seek(0)\n",
    "    return buf\n",
    "\n",
    "def predict(logmel_specs, mfcc_specs):\n",
    "    prediction_list = []\n",
    "    \n",
    "    for logmel, mfcc in zip(logmel_specs, mfcc_specs):\n",
    "        # Reshape log-mel specs\n",
    "        logmel_image = load_img(logmel, target_size=(300,300))\n",
    "        logmel_image = img_to_array(logmel_image)\n",
    "        logmel_normalized = logmel_image / 255.0\n",
    "        logmel_normalized = logmel_normalized.reshape((1, logmel_normalized.shape[0], logmel_normalized.shape[1], logmel_normalized.shape[2]))\n",
    "        # Reshape MFCC specs\n",
    "        mfcc_image = load_img(mfcc, target_size=(300,300))\n",
    "        mfcc_image = img_to_array(mfcc_image)\n",
    "        mfcc_normalized = mfcc_image / 255.0\n",
    "        mfcc_normalized = mfcc_normalized.reshape((1, mfcc_normalized.shape[0], mfcc_normalized.shape[1], mfcc_normalized.shape[2]))\n",
    "        # Predict\n",
    "        prediction_list.append(model.predict([logmel_normalized, mfcc_normalized]))\n",
    "    return prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0881452-8fb6-4dd0-951c-ea4c8bed027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1] in ALLOWED_EXTENSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdfd6fd-dc9e-4c0d-ade4-7f0d849b8464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "model = load_model('./saved_models/fine-tuning_siamese-vgg19_logmel+mfcc_30epochs_6.h5', compile=False)\n",
    "\n",
    "@app.route('/index/')\n",
    "def index():\n",
    "    return render_template('base.html')\n",
    "\n",
    "@app.route('/upload_and_classify/')\n",
    "def upload_and_classify():\n",
    "    return render_template('upload_and_classify.html')\n",
    "\n",
    "@app.route('/api/audio', methods=['POST'])\n",
    "def upload_audio():\n",
    "    if 'audio' not in request.files:\n",
    "        return render_template('base.html', prediction='No posted audio.')\n",
    "    file = request.files['audio']\n",
    "    \n",
    "    if file.filename == '':\n",
    "        return render_template('base.html', prediction='You did not select an audio.')\n",
    "    \n",
    "    if file and allowed_file(file.filename):\n",
    "        filename = secure_filename(file.filename)\n",
    "        print(\"***\"+filename)\n",
    "        \n",
    "        \"\"\"\n",
    "        Step 1: Read audio file\n",
    "        Step 2: Splice audio file into 1.92s chunks\n",
    "        Step 3: Remove chunks < 1.92\n",
    "        Step 4: Convert chunks into Spectrogram images\n",
    "        Step 5: Get prediction for each image\n",
    "        Step 6: Get average prediction \n",
    "        Step 7: Display results\n",
    "        \"\"\"\n",
    "        \n",
    "        predictions = predict(convert_logmel(splice(file)), convert_mfcc(splice(file)))\n",
    "        file.seek(0)\n",
    "        \n",
    "        logmel_image = convert_logmel_display(BytesIO(file.read()))\n",
    "        file.seek(0)\n",
    "        mfcc_image = convert_mfcc_display(BytesIO(file.read()))\n",
    "        \n",
    "        logmel_image = base64.b64encode(logmel_image.getvalue())\n",
    "        mfcc_image = base64.b64encode(mfcc_image.getvalue())\n",
    "        \n",
    "        # # Encode the image file\n",
    "        # encoded_img_data = base64.b64encode(buf.getvalue())\n",
    "        \n",
    "        # Convert prediction to list\n",
    "        # lst = [arr.tolist()[0] for arr in predictions]\n",
    "        # # Un-nest the list\n",
    "        # lst = [item for sublist in lst for item in sublist]\n",
    "        \n",
    "        concatenated_array = np.concatenate(predictions, axis=0)\n",
    "\n",
    "        average_values = np.mean(concatenated_array, axis=0)\n",
    "        \n",
    "        return render_template('base.html', logmel_image=logmel_image.decode('utf-8'), mfcc_image=mfcc_image.decode('utf-8'), prediction = json.dumps(average_values.tolist()))\n",
    "    else:\n",
    "        return render_template('base.html', prediction='Invalid File')\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
